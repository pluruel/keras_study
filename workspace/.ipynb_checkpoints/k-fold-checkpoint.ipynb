{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/boston_housing.npz\n",
      "57344/57026 [==============================] - 0s 3us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(404, 13)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "        from keras.datasets import boston_housing\n",
    "\n",
    "(train_data, train_targets), (test_data, test_targets) = boston_housing.load_data()\n",
    "\n",
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = train_data.mean(axis=0)\n",
    "train_data-= mean\n",
    "std = train_data.std(axis=0)\n",
    "train_data /= std\n",
    "\n",
    "test_data -= mean\n",
    "test_data /= std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.55369355, -0.48361547,  1.0283258 , ...,  0.78447637,\n",
       "        -3.48459553,  2.25092074],\n",
       "       [-0.39242675, -0.48361547, -0.16087773, ..., -0.30759583,\n",
       "         0.42733126,  0.47880119],\n",
       "       [-0.39982927, -0.48361547, -0.86940196, ...,  0.78447637,\n",
       "         0.44807713, -0.41415936],\n",
       "       ...,\n",
       "       [-0.20709507, -0.48361547,  1.24588095, ..., -1.71818909,\n",
       "         0.37051949, -1.49344089],\n",
       "       [-0.36698601, -0.48361547, -0.72093526, ..., -0.48960787,\n",
       "         0.39275481, -0.41829982],\n",
       "       [-0.0889679 , -0.48361547,  1.24588095, ..., -1.71818909,\n",
       "        -1.21946544, -0.40449827]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.27224633, -0.48361547, -0.43576161, ...,  1.14850044,\n",
       "         0.44807713,  0.8252202 ],\n",
       "       [-0.40342651,  2.99178419, -1.33391162, ..., -1.71818909,\n",
       "         0.43190599, -1.32920239],\n",
       "       [ 0.1249402 , -0.48361547,  1.0283258 , ...,  0.78447637,\n",
       "         0.22061726, -1.30850006],\n",
       "       ...,\n",
       "       [-0.40202987,  0.99079651, -0.7415148 , ..., -0.71712291,\n",
       "         0.07943894, -0.67776904],\n",
       "       [-0.17292018, -0.48361547,  1.24588095, ..., -1.71818909,\n",
       "        -0.98764362,  0.42083466],\n",
       "       [-0.40422614,  2.04394792, -1.20161456, ..., -1.30866202,\n",
       "         0.23317118, -1.15392266]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "def build_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(64, activation='relu', input_shape=(train_data.shape[1],)))\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(1))\n",
    "    model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folds #  0\n",
      "folds #  1\n",
      "folds #  2\n",
      "folds #  3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "k = 4\n",
    "\n",
    "num_val_samples = len(train_data) // k\n",
    "\n",
    "num_epochs = 500\n",
    "\n",
    "all_mae_histories = []\n",
    "\n",
    "for i in range(k):\n",
    "    print('folds # ', i)\n",
    "    s = i*num_val_samples\n",
    "    e = (i+1)*num_val_samples\n",
    "    \n",
    "    val_data = train_data[s:e]\n",
    "    val_targets = train_targets[s:e]\n",
    "    partial_train_data = np.concatenate([train_data[:s], train_data[e:]], axis=0)\n",
    "    partial_train_targets = np.concatenate([train_data[:s], train_data[e:]], axis=0)\n",
    "    \n",
    "    model = build_model()\n",
    "    history = model.fit(partial_train_data, partial_train_targets, validation_data = (val_data, val_targets), epochs=num_epochs, batch_size=1, verbose=0)\n",
    "    \n",
    "#     val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=0)\n",
    "    mae_history = history.history['mae']\n",
    "    \n",
    "    all_mae_histories.append(mae_history)\n",
    "    \n",
    "    average_mae_history = [np.mean([x[i] for x in all_mae_histories]) for i in range(num_epochs)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_mae_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.394625663757324"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(all_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history_dict = history.history\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "acc = history_dict['acc']\n",
    "val_acc = history_dict['val_acc']\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
